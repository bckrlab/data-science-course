{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49316708-036d-4fc0-8ac7-e847b55146df",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "source": [
    "# General Terms and First Regression Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900f889b-30c9-4c82-b729-1295e2022ff1",
   "metadata": {},
   "source": [
    "## General Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5995652a-a12f-434a-bbed-3c378dce7928",
   "metadata": {},
   "source": [
    "a. Define Knowledge Discovery in Databases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a84273-97d5-4bab-873a-906528c24261",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ebb2b50-5d67-4d21-a8ff-bef9d8b42098",
   "metadata": {},
   "source": [
    "b. What is the difference between data mining and knowledge discovery (based on the definitions used in the lecture slides)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce47ea-3d7f-4e26-a2b4-12aefd1d0cdc",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f439c9f-5cb4-4bc6-bca8-75945653f565",
   "metadata": {},
   "source": [
    "c. List four typical tasks in the context of the Modeling phase in CRISP-DM and briefly describe them based on a quick web search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a122b1b-4ab6-4fc1-a536-d3e4af2113ca",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed89bd3b-2b3f-45e2-ad76-5eb0d9675da1",
   "metadata": {},
   "source": [
    "d. List and shortly explain the three properties of data with which [De Mauro et al. 2016] defines Big Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa23df-60ed-4d3a-a402-0107de1b316d",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47dac8f3-1723-485a-b8ac-894a9dc7924a",
   "metadata": {},
   "source": [
    "### CRISP-DM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6de039-0a1a-4757-b86d-32a28a77941f",
   "metadata": {},
   "source": [
    "a. List the six phases of the CRISP-DM model and describe them in bullet points!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4bb2eb-09b8-476d-b330-53fc6faeec79",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e4fe0e0-a127-4e27-bbc3-b41c53c2c396",
   "metadata": {},
   "source": [
    "b. How is the Data Preparation phase linked to the other phases conceptually?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b5e2b6-8251-4b5b-9218-c30a4002b9b3",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "300e735f-dd6a-459a-b9b2-e9493abe2973",
   "metadata": {},
   "source": [
    "c. What happens in the Evaluation phase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a428ef0c-9f1f-412b-a16b-e2025ad91cf6",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23d5d772-fe85-4e0e-a15f-e86d2834ec03",
   "metadata": {},
   "source": [
    "## Regression: House Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a210dd2e-0ded-43a9-ab3c-9762833de157",
   "metadata": {},
   "source": [
    "In this set of exercises, we will work on a task that aims to predict housing prices from variables describing homes.\n",
    "The task is based on a [Kaggle Competition](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques). \n",
    "Here is a more detailed description of the task:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85980fd-3e46-47e9-add0-c47d66eb46d8",
   "metadata": {},
   "source": [
    "> Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    ">\n",
    "> With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n",
    "\n",
    "A [detailed description of the data](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data) can be found on [Kaggle](https://www.kaggle.com/). Additional information is included in the file `exercise_02_data_description.txt`, which you can find in the StudIP course material together with the dataset in `exercise_02_train.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeb3f15",
   "metadata": {},
   "source": [
    "a. Take a look at `exercise_02_data_description.txt`! Which data property of Big Data does this indicate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df1c2c",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "907d4152",
   "metadata": {},
   "source": [
    "b. Now also skim the dataset in `exercise_02_train.csv`! Do you conclude that the task of predicting housing prices can be considered Big Data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe8603",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "599c9f86-83c6-436f-b658-4cbcddebdff7",
   "metadata": {},
   "source": [
    "### A minimal Data Science workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ec328-2551-4b97-a0bc-cd75526bf23d",
   "metadata": {},
   "source": [
    "Suppose you have tried to solve the above problem of predicting housing prices from features of houses, but you didn't finish.\n",
    "The project was on hold for a couple of weeks, but now you are trying to reapproach it.\n",
    "The following code is what you have so far.\n",
    "\n",
    "Let's first try to understand the code in its current state.\n",
    "Afterwards we can figure out how to continue.\n",
    "\n",
    "1. Read through the code in the next cell and briefly answer the following questions to make sure you understand what is going on!\n",
    "   1. What are `X` and `y`?\n",
    "   2. What is stored in `numeric_variables`?\n",
    "   3. What is the shape of a `pandas.DataFrame`? (e.g. line `19`)\n",
    "   4. What are \"NAs\"? (Hint: You may look up the documentation of `pandas.DataFrame.isna`.)\n",
    "   5. What is stored in `n_na`? (Hint: This one may be more tricky than it looks at first glance. Have a look at line `23`!)\n",
    "   6. What do the Python expressions do that are written in curly braces in some strings? (Hint: There is an `f` in front of those strings. Weird `f-strings`...)\n",
    "   7. What does the \"list comprehension\" in line `36` do?\n",
    "\n",
    "2. You know what the code does on a step-by-step level now. Let's \"zoom out\" to get a bigger picture. Answer the following questions!\n",
    "   1. Map the steps of the CRISP-DM onto the code below! Give the start and end lines of each step!\n",
    "   2. Some steps are missing. Is there maybe a step that we have already done, that is not included in the code? (Hint: We do not worry about Deployment in this exercise.)\n",
    "\n",
    "3. By understanding what you left behind when you last approached this problem, we have taken on the mind of a Data Scientist. Now let's do some Data Science!\n",
    "   1. Run the code below!\n",
    "   2. Inspect the output and ask yourself the following questions! (You may ignore the error message for now.)\n",
    "      1. How many variables (in percent) do we loose if we only use numeric variables?\n",
    "      2. How many variables (in percent) do we loose if we drop all variables that have NAs?\n",
    "      3. How many samples do we loose (in percent) if we drop all samples that contain NAs?\n",
    "      4. How many variables do we have left if we only use numeric variables and drop all variables with NAs?\n",
    "   3. Inspect the error message and answer the following questions! (You are encouraged to use an LLM for this step.)\n",
    "      1. Is the error related to any other output?\n",
    "      2. Check out the documentation of the used model [here](https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares)! Do you see a reason why the data might not be suitable for this model?\n",
    "      3. What needs to be done conceptually in order to solve the error? (Hint: Consider the model type fixed, so it's not the problem. Think about how to adapt the data in order to fit the model.)\n",
    "      4. Implement that fix and run the code again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8feb5f-8b11-4f35-a98d-1c634da28af2",
   "metadata": {
    "mystnb": {
     "number_source_lines": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following variables are numeric:\n",
      "  00. MSSubClass\n",
      "  01. LotFrontage\n",
      "  02. LotArea\n",
      "  03. OverallQual\n",
      "  04. OverallCond\n",
      "  05. YearBuilt\n",
      "  06. YearRemodAdd\n",
      "  07. MasVnrArea\n",
      "  08. BsmtFinSF1\n",
      "  09. BsmtFinSF2\n",
      "  10. BsmtUnfSF\n",
      "  11. TotalBsmtSF\n",
      "  12. 1stFlrSF\n",
      "  13. 2ndFlrSF\n",
      "  14. LowQualFinSF\n",
      "  15. GrLivArea\n",
      "  16. BsmtFullBath\n",
      "  17. BsmtHalfBath\n",
      "  18. FullBath\n",
      "  19. HalfBath\n",
      "  20. BedroomAbvGr\n",
      "  21. KitchenAbvGr\n",
      "  22. TotRmsAbvGrd\n",
      "  23. Fireplaces\n",
      "  24. GarageYrBlt\n",
      "  25. GarageCars\n",
      "  26. GarageArea\n",
      "  27. WoodDeckSF\n",
      "  28. OpenPorchSF\n",
      "  29. EnclosedPorch\n",
      "  30. 3SsnPorch\n",
      "  31. ScreenPorch\n",
      "  32. PoolArea\n",
      "  33. MiscVal\n",
      "  34. MoSold\n",
      "  35. YrSold\n",
      "  36. SalePrice\n",
      "46.84% of all variables are numeric.\n",
      "This means, we loose 53.16 if we only keep numeric variables.\n",
      "LotFrontage      259\n",
      "Alley           1369\n",
      "MasVnrType       872\n",
      "MasVnrArea         8\n",
      "BsmtQual          37\n",
      "BsmtCond          37\n",
      "BsmtExposure      38\n",
      "BsmtFinType1      37\n",
      "BsmtFinType2      38\n",
      "Electrical         1\n",
      "FireplaceQu      690\n",
      "GarageType        81\n",
      "GarageYrBlt       81\n",
      "GarageFinish      81\n",
      "GarageQual        81\n",
      "GarageCond        81\n",
      "PoolQC          1453\n",
      "Fence           1179\n",
      "MiscFeature     1406\n",
      "dtype: int64\n",
      "24.05% of all variables contain NAs.\n",
      "This means, we loose 75.95% of all variables if we only keep variables without NAs.\n",
      "100.00% of all samples contain NAs.\n",
      "This means, we loose 100.00% if we drop all samples with NAs.\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_150157/1370243486.py:37: FutureWarning: Logical ops (and, or, xor) between Pandas objects and dtype-less sequences (e.g. list, tuple) are deprecated and will raise in a future version. Wrap the object in a Series, Index, or np.array before operating instead.\n",
      "  mask_selected = mask_number & ~mask_na\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'RL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_150157/1370243486.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mmask_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_number\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mmask_na\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_selected\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data-science-ws-24-25/lib/python3.13/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/data-science-ws-24-25/lib/python3.13/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    610\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data-science-ws-24-25/lib/python3.13/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data-science-ws-24-25/lib/python3.13/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         raise ValueError(\n\u001b[1;32m   1298\u001b[0m             \u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mestimator_name\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m requires y to be passed, but the target y is None\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1302\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data-science-ws-24-25/lib/python3.13/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1009\u001b[0m                         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n\u001b[1;32m   1015\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 \u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data-science-ws-24-25/lib/python3.13/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data-science-ws-24-25/lib/python3.13/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'RL'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "data_houses = pd.read_csv(\n",
    "    \"exercise_02_train.csv\", \n",
    "    index_col=\"Id\")\n",
    "\n",
    "X = data_houses.drop(columns=\"SalePrice\")\n",
    "y = data_houses[\"SalePrice\"]\n",
    "\n",
    "numeric_variables = data_houses.select_dtypes(np.number).columns\n",
    "\n",
    "print(f\"The following variables are numeric:\")\n",
    "for i, c in enumerate(numeric_variables):\n",
    "    print(f\"  {i:02d}.\", c)\n",
    "\n",
    "percent_numeric = numeric_variables.size / X.shape[1] * 100\n",
    "print(f\"{percent_numeric:.02f}% of all variables are numeric.\") \n",
    "print(f\"This means, we loose {100 - percent_numeric:.02f} if we only keep numeric variables.\")\n",
    "\n",
    "n_na = X.isna().sum()\n",
    "mask_na = n_na > 0\n",
    "print(n_na[mask_na])\n",
    "\n",
    "percent_na = mask_na.sum() / X.shape[1] * 100\n",
    "print(f\"{percent_na:.02f}% of all variables contain NAs.\")\n",
    "print(f\"This means, we loose {100 - percent_na:.02f}% of all variables if we only keep variables without NAs.\")\n",
    "\n",
    "n_na_samples = X.shape[0] - X.dropna().shape[0]\n",
    "percent_na_samples = n_na_samples / X.shape[0] * 100\n",
    "print(f\"{percent_na_samples:.02f}% of all samples contain NAs.\")\n",
    "print(f\"This means, we loose {percent_na_samples:.02f}% if we drop all samples with NAs.\")\n",
    "\n",
    "mask_number = [c in numeric_variables for c in X.columns]\n",
    "mask_selected = mask_number & ~mask_na\n",
    "print(X.loc[:,mask_selected].shape[1])\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "mean_absolute_error(y, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-ws-24-25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

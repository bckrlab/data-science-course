{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa77a437",
   "metadata": {},
   "source": [
    "# 02: Learning from Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f8f46a",
   "metadata": {},
   "source": [
    "## Warmup\n",
    "\n",
    "To warm up, you will define the weights of a perceptron manually.\n",
    "\n",
    "Have a look at the toy dataset, that the following code gives you.\n",
    "\n",
    "1. Define the weights of the perceptron where the code asks you to fill in the `manual_weights` array.\n",
    "\n",
    "The code cell after that gives you a plot that lets you check what your perceptron is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bddf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd93b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a toy dataset\n",
    "AND_data = pd.DataFrame({\"x1\": [0., 0., 1., 1.], \"x2\": [0., 1., 0., 1.], \"y\": [-1, -1, -1, +1]})\n",
    "label_col = \"y\"\n",
    "print(\"--- data ---\")\n",
    "print(AND_data.head())\n",
    "print(\"------------\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e6e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(df):\n",
    "    plt.scatter(df[\"x1\"], df[\"x2\"], c=df[\"y\"])\n",
    "    plt.xlim(-1, 2)\n",
    "    plt.ylim(-1, 2)\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.show()\n",
    "\n",
    "# visualizing our toy data\n",
    "plot_data(AND_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c6004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, weights) -> None:\n",
    "        self.weights = weights\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        return np.sign(x.dot(self.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e1b5c",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": [
    "manual_weights = np.array([])  # TODO: fill the array\n",
    "manual_perceptron = Perceptron(manual_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26447787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perceptron_on_data(perceptron, df):\n",
    "    line = np.array([[x1, -(perceptron.weights[0] + x1*perceptron.weights[1])/perceptron.weights[2]] for x1 in np.linspace(-1, 2, 2)])\n",
    "\n",
    "    plt.scatter(df[\"x1\"], df[\"x2\"], c=df[\"y\"])\n",
    "    line_artist = plt.plot(line[:, 0], line[:, 1])[0]\n",
    "    plt.xlim(-1, 2)\n",
    "    plt.ylim(-1, 2)\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.legend([line_artist], [\"Perceptron\"])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_perceptron_on_data(manual_perceptron, AND_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43289bfc",
   "metadata": {},
   "source": [
    "2. Is this a supervised or unsupervised learning problem?\n",
    "3. What is the learning task in this problem called?\n",
    "4. Complete the hypothesis set definition to match your mental model selection process from the first task in this section. (Do it in handwriting if you do not know $\\LaTeX$ syntax.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d86fa9",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "source": [
    "2. Supervised/Unsupervised (remove the wrong one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6383859",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "source": [
    "3. Learning task: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0279ec",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "source": [
    "4. Hypothesis set:\n",
    "$$\\mathcal{H} = \\{\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6a404",
   "metadata": {},
   "source": [
    "## Perceptron Learning Algorithm (PLA)\n",
    "\n",
    "Let's start by implementing the perceptron learning algorithm from the lecture.\n",
    "\n",
    "1. Rename the variable `something` to how it is called in the lecture's pseudo code.\n",
    "2. Complete the function implementation.\n",
    "    - Use the code cell after that to plot your perceptron and verify your implementation.\n",
    "3. Now you should see a line in that plot. The plot calls it `Perceptron`, but what is this really called?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffc7a15",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "source": [
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa160d",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": [
    "def PLA(D: pd.DataFrame, label_col=\"y\"):\n",
    "    if len(D) == 0:\n",
    "        raise Exception(\"Training data cannot be empty, but it is.\")\n",
    "    \n",
    "    d = len(D.columns)-1\n",
    "    X = np.ones(shape=(len(D), d+1))\n",
    "    X[:, 1:] = D[D.columns[D.columns != label_col]]\n",
    "    Y = np.array(D[label_col])\n",
    "    w = np.random.random(d+1)\n",
    "\n",
    "    something = np.sign(X.dot(w)) != Y  # TODO: Start by renaming this variable. What is this?\n",
    "    \n",
    "    # TODO: add your code here\n",
    "    \n",
    "    return lambda x: np.sign(x.dot(w)), w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311cff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLA_weights = PLA(AND_data, label_col)\n",
    "print(\"w =\", PLA_weights)\n",
    "PLA_perceptron = Perceptron(PLA_weights)\n",
    "\n",
    "plot_perceptron_on_data(PLA_perceptron, AND_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d08ca1d",
   "metadata": {},
   "source": [
    "## Linear Separability\n",
    "\n",
    "The criterion that tells us whether the PLA can fit a dataset is called linear separability.\n",
    "\n",
    "1. Fill in the following mathematical expression where there are underscores, so that it defines linear separability. (Do it in handwriting if you do not know $\\LaTeX$ syntax.)\n",
    "2. Update point 3 from our previous toy dataset in the following code cell to the closest possible point, such that the data is no longer linearly separable.\n",
    "3. How does your PLA implementation from above behave on this new data?\n",
    "4. Copy your PLA implementation to the function `PLA_robust` below. Now change the loop condition to avoid this problem. Feel free to change the function signature as you see fit.\n",
    "5. Obtain a perceptron from your function `PLA_robust` for a new dataset by running the last code cell in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6f577",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "source": [
    "1. We call a dataset $D = \\{(x_n, y_n) \\mid x_n \\in \\_, y_n \\in \\_\\}^N_{n=1}$ linearly separable, iff\n",
    "$$\\exists \\_ \\in \\_ \\forall (x_i, y_i) \\in D: \\_ = y_i.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ad550",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "source": [
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bc2556",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": [
    "not_linearly_separable_data = AND_data.copy()\n",
    "not_linearly_separable_data.loc[3, \"x1\"] = 1  # TODO: change value\n",
    "not_linearly_separable_data.loc[3, \"x2\"] = 1  # TODO: change value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe725931",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(not_linearly_separable_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a048256",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "outputs": [],
   "source": [
    "def PLA_robust(D: pd.DataFrame, label_col=\"y\"):\n",
    "    pass  # TODO: implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e69005",
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs_xs, blobs_ys = make_blobs(100, 2, centers=[[0, 0], [0, 1], [1, 0], [1, 1]], cluster_std=.5)\n",
    "noisy_AND_data = pd.DataFrame({\"x1\": blobs_xs[:, 0], \"x2\": blobs_xs[:, 1], \"y\": [1 if y == 3 else -1 for y in blobs_ys]})\n",
    "\n",
    "PLA_robust_weights = PLA_robust(noisy_AND_data, label_col)\n",
    "print(\"w =\", PLA_robust_weights)\n",
    "PLA_robust_perceptron = Perceptron(PLA_robust_weights)\n",
    "\n",
    "plot_perceptron_on_data(PLA_robust_perceptron, noisy_AND_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e337f450",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "The confusion matrix is the basis for common classification model evaluation.\n",
    "\n",
    "1. Run the following code to obtain a confusion matrix for the perceptron you have just trained.\n",
    "2. Which cell in this matrix relates to which area in this figure: [https://commons.wikimedia.org/wiki/File:Precisionrecall.svg](https://commons.wikimedia.org/wiki/File:Precisionrecall.svg)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb3fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat = confusion_matrix([PLA_robust_perceptron.predict(np.array([[1, row[0], row[1]]])) for row in noisy_AND_data.itertuples(index=False)], noisy_AND_data[\"y\"])\n",
    "confmat_display = ConfusionMatrixDisplay(confmat)\n",
    "confmat_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e45d59d",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "source": [
    "2. Relations to Wikipedia figure\n",
    "- top-left: \n",
    "- top-right: \n",
    "- bottom-left: \n",
    "- bottom-right: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c24456",
   "metadata": {},
   "source": [
    "## Bonus: Elements of learning\n",
    "\n",
    "Let's look at the final learning setup again, where you applied the `PLA_robust` learning algorithm to the noisy data, and determine the main elements that were involved.\n",
    "\n",
    "Some questions will be tough to answer. Seek a discussion with fellow student or the class tutor if you feel there is no definitive answer.\n",
    "\n",
    "1. Map the definition of a learning algorithm to this setup.\n",
    "    1. What is the task T?\n",
    "    2. What is the experience E?\n",
    "    3. What is the performance measure P?\n",
    "2. Map the elements of the \"learning setup diagram\" from the lecture to this setup.\n",
    "    1. What is the target function?\n",
    "    2. What are the training examples?\n",
    "    3. What is the hypothesis set?\n",
    "    4. What is the learning algorithm?\n",
    "    5. What is the final hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a0f395",
   "metadata": {
    "tags": [
     "placeholder"
    ]
   },
   "source": [
    "1.\n",
    "    1.\n",
    "    2.\n",
    "    3.\n",
    "\n",
    "2.\n",
    "    1.\n",
    "    2.\n",
    "    3.\n",
    "    4.\n",
    "    5."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-ws-25-26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
